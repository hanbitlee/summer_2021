{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gat.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGGQQARJSCaJVi/0ZrV5e4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanbitlee/summer_2021/blob/main/gat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU4foXjRvTBy",
        "outputId": "ca222189-5b90-4800-9bfb-bf5ee2e42050"
      },
      "source": [
        "!pip install dgl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dgl in /usr/local/lib/python3.7/dist-packages (0.6.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.19.5)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.1->dgl) (4.4.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2021.5.30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVlKs5mSWLwL"
      },
      "source": [
        "from dgl.nn.pytorch import GATConv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB2CkYO9WO_R"
      },
      "source": [
        "class GATLayer(nn.Module):\n",
        "    def __init__(self, g, in_dim, out_dim):\n",
        "        super(GATLayer, self).__init__()\n",
        "        self.g = g\n",
        "        # equation (1)\n",
        "        self.fc = nn.Linear(in_dim, out_dim, bias=False)\n",
        "        # equation (2)\n",
        "        self.attn_fc = nn.Linear(2 * out_dim, 1, bias=False)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
        "        gain = nn.init.calculate_gain('relu')\n",
        "        nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
        "        nn.init.xavier_normal_(self.attn_fc.weight, gain=gain)\n",
        "\n",
        "    def edge_attention(self, edges):\n",
        "        # edge UDF for equation (2)\n",
        "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
        "        a = self.attn_fc(z2)\n",
        "        return {'e': F.leaky_relu(a)}\n",
        "\n",
        "    def message_func(self, edges):\n",
        "        # message UDF for equation (3) & (4)\n",
        "        return {'z': edges.src['z'], 'e': edges.data['e']}\n",
        "\n",
        "    def reduce_func(self, nodes):\n",
        "        # reduce UDF for equation (3) & (4)\n",
        "        # equation (3)\n",
        "        alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
        "        # equation (4)\n",
        "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
        "        return {'h': h}\n",
        "\n",
        "    def forward(self, h):\n",
        "        # equation (1)\n",
        "        z = self.fc(h)\n",
        "        self.g.ndata['z'] = z\n",
        "        # equation (2)\n",
        "        self.g.apply_edges(self.edge_attention)\n",
        "        # equation (3) & (4)\n",
        "        self.g.update_all(self.message_func, self.reduce_func)\n",
        "        return self.g.ndata.pop('h')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2n1vB12WyGF"
      },
      "source": [
        "def edge_attention(self, edges):\n",
        "    # edge UDF for equation (2)\n",
        "    z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
        "    a = self.attn_fc(z2)\n",
        "    return {'e' : F.leaky_relu(a)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mipZZupW1OB"
      },
      "source": [
        "def reduce_func(self, nodes):\n",
        "    # reduce UDF for equation (3) & (4)\n",
        "    # equation (3)\n",
        "    alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
        "    # equation (4)\n",
        "    h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
        "    return {'h' : h}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-d1wLGfXNUp"
      },
      "source": [
        "class MultiHeadGATLayer(nn.Module):\n",
        "    def __init__(self, g, in_dim, out_dim, num_heads, merge='cat'):\n",
        "        super(MultiHeadGATLayer, self).__init__()\n",
        "        self.heads = nn.ModuleList()\n",
        "        for i in range(num_heads):\n",
        "            self.heads.append(GATLayer(g, in_dim, out_dim))\n",
        "        self.merge = merge\n",
        "\n",
        "    def forward(self, h):\n",
        "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
        "        if self.merge == 'cat':\n",
        "            # concat on the output feature dimension (dim=1)\n",
        "            return torch.cat(head_outs, dim=1)\n",
        "        else:\n",
        "            # merge using average\n",
        "            return torch.mean(torch.stack(head_outs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AduxGtL0W441"
      },
      "source": [
        "class GAT(nn.Module):\n",
        "    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads):\n",
        "        super(GAT, self).__init__()\n",
        "        self.layer1 = MultiHeadGATLayer(g, in_dim, hidden_dim, num_heads)\n",
        "        # Be aware that the input dimension is hidden_dim*num_heads since\n",
        "        # multiple head outputs are concatenated together. Also, only\n",
        "        # one attention head in the output layer.\n",
        "        self.layer2 = MultiHeadGATLayer(g, hidden_dim * num_heads, out_dim, 1)\n",
        "\n",
        "    def forward(self, h):\n",
        "        h = self.layer1(h)\n",
        "        h = F.elu(h)\n",
        "        h = self.layer2(h)\n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyId8fbzYHVG"
      },
      "source": [
        "from dgl import DGLGraph\n",
        "from dgl.data import citation_graph as citegrh\n",
        "import networkx as nx\n",
        "\n",
        "def load_data():\n",
        "    data = citegrh.load_cora()\n",
        "    features = torch.FloatTensor(data.features)\n",
        "    labels = torch.LongTensor(data.labels)\n",
        "    mask = torch.BoolTensor(data.train_mask)\n",
        "    g = DGLGraph(data.graph)\n",
        "    return g, features, labels, mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jwZ8kjlfvPF"
      },
      "source": [
        "def accuracy(logits, labels):\n",
        "    _, indices = torch.max(logits, dim=1)\n",
        "    correct = torch.sum(indices == labels)\n",
        "    return correct.item() * 1.0 / len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVMzJFeSfy5V"
      },
      "source": [
        "def evaluate(model, features, labels, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(features)\n",
        "        logits = logits[mask]\n",
        "        labels = labels[mask]\n",
        "        return accuracy(logits, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ANPWY8kXAEI",
        "outputId": "11483641-8291-480f-d9df-8abcc4a89ee5"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# create the model, 2 heads, each head has hidden size 8\n",
        "\n",
        "g, features, labels, mask = load_data()\n",
        "\n",
        "net = GAT(g,\n",
        "          in_dim=features.size()[1],\n",
        "          hidden_dim=8,\n",
        "          out_dim=7,\n",
        "          num_heads=2)\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
        "\n",
        "# main loop\n",
        "dur = []\n",
        "for epoch in range(30):\n",
        "    if epoch >= 3:\n",
        "        t0 = time.time()\n",
        "\n",
        "    logits = net(features)\n",
        "    logp = F.log_softmax(logits, 1)\n",
        "    loss = F.nll_loss(logp[mask], labels[mask])\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch >= 3:\n",
        "        dur.append(time.time() - t0)\n",
        "\n",
        "    acc = accuracy(logits[mask], labels[mask])\n",
        "    print(\"Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n",
        "            epoch, loss.item(), acc, np.mean(dur)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n",
            "Epoch 00000 | Loss 1.9447 | Test Acc 0.1857 | Time(s) nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.feat will be deprecated, please use g.ndata['feat'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.7/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.label will be deprecated, please use g.ndata['label'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.7/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.train_mask will be deprecated, please use g.ndata['train_mask'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.7/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.graph will be deprecated, please use dataset[0] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.7/dist-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
            "  return warnings.warn(message, category=category, stacklevel=1)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00001 | Loss 1.9425 | Test Acc 0.2286 | Time(s) nan\n",
            "Epoch 00002 | Loss 1.9403 | Test Acc 0.2857 | Time(s) nan\n",
            "Epoch 00003 | Loss 1.9381 | Test Acc 0.3071 | Time(s) 0.1106\n",
            "Epoch 00004 | Loss 1.9359 | Test Acc 0.3643 | Time(s) 0.1117\n",
            "Epoch 00005 | Loss 1.9337 | Test Acc 0.4071 | Time(s) 0.1140\n",
            "Epoch 00006 | Loss 1.9315 | Test Acc 0.4357 | Time(s) 0.1131\n",
            "Epoch 00007 | Loss 1.9294 | Test Acc 0.4929 | Time(s) 0.1139\n",
            "Epoch 00008 | Loss 1.9272 | Test Acc 0.5214 | Time(s) 0.1161\n",
            "Epoch 00009 | Loss 1.9249 | Test Acc 0.5857 | Time(s) 0.1202\n",
            "Epoch 00010 | Loss 1.9227 | Test Acc 0.6214 | Time(s) 0.1187\n",
            "Epoch 00011 | Loss 1.9205 | Test Acc 0.6571 | Time(s) 0.1179\n",
            "Epoch 00012 | Loss 1.9183 | Test Acc 0.6929 | Time(s) 0.1170\n",
            "Epoch 00013 | Loss 1.9161 | Test Acc 0.7286 | Time(s) 0.1175\n",
            "Epoch 00014 | Loss 1.9138 | Test Acc 0.7571 | Time(s) 0.1176\n",
            "Epoch 00015 | Loss 1.9116 | Test Acc 0.8000 | Time(s) 0.1180\n",
            "Epoch 00016 | Loss 1.9093 | Test Acc 0.8071 | Time(s) 0.1175\n",
            "Epoch 00017 | Loss 1.9071 | Test Acc 0.8286 | Time(s) 0.1177\n",
            "Epoch 00018 | Loss 1.9048 | Test Acc 0.8500 | Time(s) 0.1172\n",
            "Epoch 00019 | Loss 1.9025 | Test Acc 0.8571 | Time(s) 0.1170\n",
            "Epoch 00020 | Loss 1.9002 | Test Acc 0.8571 | Time(s) 0.1166\n",
            "Epoch 00021 | Loss 1.8979 | Test Acc 0.8786 | Time(s) 0.1163\n",
            "Epoch 00022 | Loss 1.8956 | Test Acc 0.9000 | Time(s) 0.1159\n",
            "Epoch 00023 | Loss 1.8933 | Test Acc 0.9071 | Time(s) 0.1159\n",
            "Epoch 00024 | Loss 1.8910 | Test Acc 0.9071 | Time(s) 0.1160\n",
            "Epoch 00025 | Loss 1.8886 | Test Acc 0.9143 | Time(s) 0.1158\n",
            "Epoch 00026 | Loss 1.8862 | Test Acc 0.9143 | Time(s) 0.1155\n",
            "Epoch 00027 | Loss 1.8839 | Test Acc 0.9214 | Time(s) 0.1153\n",
            "Epoch 00028 | Loss 1.8815 | Test Acc 0.9214 | Time(s) 0.1152\n",
            "Epoch 00029 | Loss 1.8791 | Test Acc 0.9214 | Time(s) 0.1154\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}